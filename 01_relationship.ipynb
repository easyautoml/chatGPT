{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b82ff9-5243-4bee-883e-32b1d0c1a9d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name util",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the SpaCy English model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\allgpt\\lib\\site-packages\\spacy\\__init__.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prefer_gpu, require_gpu, require_cpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m info  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglossary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\allgpt\\lib\\site-packages\\spacy\\pipeline\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattributeruler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttributeRuler\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdep_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DependencyParser\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01medit_tree_lemmatizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditTreeLemmatizer\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\allgpt\\lib\\site-packages\\spacy\\pipeline\\attributeruler.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrsly\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipe\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Example\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\allgpt\\lib\\site-packages\\spacy\\pipeline\\pipe.pyx:1\u001b[0m, in \u001b[0;36minit spacy.pipeline.pipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\allgpt\\lib\\site-packages\\spacy\\vocab.pyx:1\u001b[0m, in \u001b[0;36minit spacy.vocab\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\allgpt\\lib\\site-packages\\spacy\\tokens\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoken\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Token\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Span\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\allgpt\\lib\\site-packages\\spacy\\tokens\\doc.pyx:34\u001b[0m, in \u001b[0;36minit spacy.tokens.doc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name util"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the SpaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the input sentence\n",
    "sentence = \"My name is Luc, I grew up in Thanh Hoa.\"\n",
    "\n",
    "# Process the sentence with SpaCy\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Initialize variables to store the entities and their relationship\n",
    "entity1 = None\n",
    "entity2 = None\n",
    "relationship = None\n",
    "\n",
    "# Iterate through the tokens in the parsed sentence\n",
    "for token in doc:\n",
    "    # Check if the token is an entity\n",
    "    if token.ent_type_ == \"PERSON\":\n",
    "        entity1 = token.text\n",
    "    elif token.ent_type_ == \"GPE\":\n",
    "        entity2 = token.text\n",
    "\n",
    "    # Check if the token is a verb and has a subject\n",
    "    if token.dep_ == \"ROOT\":\n",
    "        relationship = token.text\n",
    "\n",
    "# Check if both entities and the relationship were found\n",
    "if entity1 and entity2 and relationship:\n",
    "    print(f\"{entity1} - {entity2}: {relationship}\")\n",
    "else:\n",
    "    print(\"Entities and relationship not found in the sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf97ed5-ef08-4b99-9d55-1b9a7ebee236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
